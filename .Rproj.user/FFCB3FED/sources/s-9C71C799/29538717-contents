---
title: "Did *X* cause *Y*?"
author: "Macartan Humphreys"
date: "May 23, 2018"
output: html_document
bibliography: bib.bib
---

```{r setup, include=FALSE}
library(knitr)
library(fabricatr)
library(dplyr)

knitr::opts_chunk$set(echo = TRUE)
```

Imagine you have infinite data on the effects of a randomized intervention  $X$  on a binary outcome $Y$. Your data looks like this: 

```{r, echo = FALSE, comment = ""}
df <- data.frame(X = c(rep(0,4), rep(1,4)),
           K = c(rep(0,6), rep(1,2)),
           Y = c(0,1,0,1,0,1,1,1))
with(df, table(X, Y))/8
```


```{r, echo = FALSE, comment = "", include = FALSE}

dawid_bounds <- function(df, XYONLY = FALSE) {

  PY1X1 <- with(filter(df, X==1), mean(Y==1))
  PY1X0 <- with(filter(df, X==0), mean(Y==1))
  PY0X0 <- with(filter(df, X==0), mean(Y==0))

  dawid_bounds_RR    <-  PY1X1/ PY1X0
  dawid_bounds_Lower <-  max(c(0, 1-(1/dawid_bounds_RR)))
  dawid_bounds_Upper <-  min(c(PY0X0, PY1X1))/PY1X1

  if(XYONLY) return(dawid_bounds =  c(dawid_bounds_Lower, dawid_bounds_Upper))

  a <- with(filter(df, X==0), mean(K==0))
  b <- with(filter(df, X==1), mean(K==1))
  c <- with(filter(df, K==0), mean(Y==0))
  d <- with(filter(df, K==1), mean(Y==1))
  if(a<=b & c <= d) num  <- a*c + (1-d)*(1-b)
  if(a<=b & c > d)  num  <- a*d + (1-c)*(1-b)
  if(a>b & c <= d)  num  <- b*c + (1-d)*(1-a)
  if(a>b & c > d)   num  <- b*d + (1-a)*(1-c)
  cbind(
    dawid_bounds_XY =  c(dawid_bounds_Lower, dawid_bounds_Upper),
    dawid_bounds_mediation = c(dawid_bounds_Lower, num/PY1X1))
  }

dawid_bounds(df)  
```

Assuming no problems with spillovers and the like this experimental data gives you grounds to make the following claim about the average effect of $X$ on $Y$: A change in $X$ from 0 to 1 produces, produces a change in $Y$ from 0.5 to 0.75, on average: so 0.25 points.

Great.

Say then someone selects a case at random from the bottom right hand cell, with $X=1, Y=1$, and asks: *what are the chances that $X$ caused $Y$ in this case?*^[Or perhaps, without selecting, they ask: "what is the share of cases with $X=Y=1$ for which $X$ caused $Y$?']

Maybe pause for a second and see how you would answer that question. 

Though it sounds like a simple question, the infinite experimental data you have available to you is just not enough to answer it. I say more on why this is below but I think it is fair to say that most experimentalists would say that they cannot answer the question. Some might wonder whether the question is even well posed.

Qualitative researchers on the other hand, using process tracing techniques and additional case level data do claim to be able to answer this question. They might tell you: If you can provide some information about what occurred on the path between $X$ and $Y$, then I will be in a better position to say whether $X$ caused $Y$ in this case. 

If you look at Bayesian formalizations of process tracing you can see it's not hard to show that one *can* make claims like this, conditional on beliefs about the informativeness of the within case data. But it has worried me for a long time how one could ever be *justified* making claims of this form. How can one *demonstrate* that within case information is informative about causal effects? 

In what follows, building on joint work with Alan Jacobs, I will (a) give a simple example that shows that it *is* possible to justify these claims using the kinds of justifications that are familiar to skeptical experimentalists (b) highlight how hard this is in general. The kind of issues involved here have been the subject of some interesting contributions by Judea Pearl and Philip Dawid around the use of evidence in judicial proceedings (I think the  best overview of results in this area might be found in @murtas2017new).

I find it encouraging that this kind of inference is possible though I still find it worrying how hard it is to justify inferences like this in general.

# What's the question?

First off is a clarification of what the *question* is. 

The question "did $X$ cause $Y$" (or, what are the chances that "X" caused "Y"?) is a "causes of $Y$" question rather than an "effects of $X$" question. It took me a while to realize this and I apologize to lots of students that I have told over the years that a "causes of $Y$" question is a question in which there is a search for $X$'s that have effects on $Y$ (see @gelman2013ask for this take on the question). But that is really just a set of effects of $X$s questions.  The distinction between a causes of effects question and an effects of causes question is sharpest when the $X$ and $Y$ are fixed. The effects of causes question is the usual question that is routinely answered by experimentalists --- what happens when $X$ changes; the effects of causes question is a question about a different estimand: given the level of $Y$, when $X$ is what it is, would $Y$ be different if $X$ were different. Formally the two estimands might be written, using potential outcomes notation, as:

$$\text{Effects of causes: } E(Y(X=1) - Y(X=0)) $$

$$\text{Causes of effects: } \Pr(Y(X=0)=0 | Y(X=1)=1, X = 1) $$
They are simply different estimands.^[The distinction is perhaps easier to see using primary strata. Say that in share $a$ of cases $X$ has a negative effect on $Y$, in share $b$ os cases it has a positive effect, in share $c$ $Y=0$ no matter what and in share $d$ $Y=1$ no matter what. Then effect of $X$ question is an inquiry about $b-a$ the cause of effect (given $X=Y=1$) question is about $\frac{b}{b+d}$.]  In some discussions, causes of effects questions are described as being case level rather than population level estimands or historical rather than perspective estimands. But these features don't get to the heart of the matter. The causes of effects question could just as easily be posed as one about the share of units for which, were they to be treated and to have a positive outcome, one could attribute the outcome to the treatment..

# Why is the causes of effects question hard to answer?

The reason is that many different answers to the question are consistent with a given distribution of $X$s and $Y$s.

The average treatment effect is 0.25. Perhaps underlying this average treatment effect is a process in which in 25% of cases X has a positive effect, in 25% of cases Y is always 0, and in 50% of cases Y is always 1. That process would give rise to this data table and if that were the process the probability that $X$ caused $Y$ for an $X=Y=1$ case would be $(0.125/0.375) = 1/3$. 

But it is also possible that underlying this data table is a process in which in 25% of cases $X$ has a negative effect on $Y$, in 50% of cases $X$ has a positive effect on $Y$, and in 25% of cases $Y=1$ no matter what. In that case the probability that $X$ caused $Y$ for an $X=Y=1$ case would be $(0.25/0.375) = 2/3$. 

Who is to say which is right? The data does not discriminate between these cases. In other words, the estimand here is not identified by experimental data. Interesting though the data does put bounds on the answer --- in fact here the bounds are just these --- the answer should be somewhere between one third and two thirds chance that $X$ is responsible for $Y$---other answers are not consistent with the data. 


# How can a process tracing approach tackle this problem?

To see how process tracing might help it is useful to see first that the answer to  causes of effects question is not always unanswerable from experimental data. Most obviously say that our infinite data told us that $Y=X$. That is, there is a perfect fit. In that case $X=1$ causes $Y=1$ and by the same token if $Y=1$ it is because $X=1$. But it is also possible to figure out attribution without perfect fits. Say the (infinite) experimental data looked like this:


```{r, echo = FALSE, comment = ""}
with(df, table(X, K))/8
```

Then it is easy to see that the share of cases in which $X$ has a negative effect is zero and the set of cases that take $Y=1$, no matter what, is also zero (as otherwise there would be data in the top right cell. But in that case all the cases in the lower left cell are cases in which $X=1$ no matter what, as are half the cases in the top left cell. The remaining 50%, split between the top left and bottom right are those cases in which there are positive effects. And so *all* the cases in $X=Y=1$ are cases in which $X$ caused $Y$. So you don;t need a perfect $R^2$ to figure out attribution, nor do you need to rule out some causal types by assumption. 
<!-- A simpler way of saying the same thing is that if that data says that $X=1$ is a necessary condition for $Y=1$ then changing $X$ changes $Y$ in $X=Y=1$ cases.  -->

Say this is the case, and that for our infinity of experiments we see that for some intermediate variable $K$ the $X$, $K$, data looks like that. And, moreover (we are assuming we are in a fortunate position), for another infinity of experiments we can see that the distribution of $K$ and $Y$ is of the form: 

```{r, echo = FALSE, comment = ""}
with(df, table(K, Y))/8
```

Note that this data table, like the $X,K$ table, also lets us figure out attribution at this step (probabilistically): there are no cases for which $X$ exerts a negative effect and none in which we would have $Y=0$ regardless. Rather, half the cases are ones in which $K$ causes $Y$ and half are ones in which $Y=1$ regardless.

Last thing: say, *in addition*,  the distribution of the (infinite) $X, Y, X$ data from the random assignment of $X$ looks just like what you get from the product of the two experiments.

```{r, echo = FALSE, include = FALSE}
kable(df)
```

<!-- Here 3/4 are in control -->
<!-- say half d half b -->

<!-- 3/8  3/8 -->
<!--      2/8 -->

     
This information is "in addition" because information about the "observational" relationship between $K$ and $Y$ (with $X$ randomized) lets us establish two key things that we couldn't establish just from the experiments of $X$ on $K$ and $K$ on $Y$. First we can now see that the effect of $X$ on $Y$ runs entirely through $K$---one can see this by noting that $Y$ is independent of $X$ conditional on $K$.  Second, the $X,Y$ distribution that arises when changes in $K$ are induced by $X$ is the same as arises when $K$ is randomly assigned (conditional on $X$). 

We are now in a position to represent the $X, K, Y$ relationship as a simple graph:

$$X\rightarrow K \rightarrow Y$$

Under these conditions  the total effect of $X$ on $Y$ (0.25) is just the product of the effect of $X$ on $K$ (0.5) and $K$ on $Y$  (0.5). (In general there  is no  guarantee that the total effect is the product of the effects at each step even when all effects of $X$ on $Y$ pass through $K$.^[For instance consider a situation with a violation of sequential ignorability. Say 
$K = ZX$ and $Y = ZK$ and $Pr(Z = 1)=.5$, then from experiments we have that $K$ has a 50% effect on $X$ and $X$ has a 50% effect on $Y$. However if $K$ is not independently manipulated then, thanks to the role played by $Z$,  it will track $X$ exactly and the $X$ on $Y$ effect will be 50%, not 25%.])

Before even looking at the value of *K* it is interesting to note that our knowledge of this process *is enough* to now give a a specific (probabilistic) answer to the question: *did $X$ cause $Y$?* That is, the quantity is now identified, even before we examine $K$. 
<!-- using abcd notation we have 50% bs and 50% cs in the XK relationship and 50% bs and 50%d in the KY relationship.  -->
There are three causal types that produce $Y=1$ given $X =1$, each equally likely, and for just one of these does $X$ cause $Y$ (the other two are  types for which $Y$ would be 1 regardless of the effects of $X$ on $K$). Thus one in three cases are caused by $X$.  These are the bounds given in  @murtas2017new.

We can go further though, using what we learn when we inspect $K$. From the experimental data we know (a) if $K=1$ then it is because $X=1$ (b) if $Y=1$ (given $X=1$) there is a 50% chance that it is because $K=1$ (c) if $K=0$ then $K=0$ did not cause $Y=1$. 

In the language of process tracing the clue $K$ is a "hoop test" for the proposition that $X$ caused $Y$. Here the "probative value" of the test is not based on a theoretical claim or subjective priors, but is **identified** in the sense that no other conclusion is consistent with the data available to researchers.

Knowledge of the process here pushes us to the lower bound of beliefs that $X$ caused $Y$ (1/3) when we observe $X=Y=1$; but finding out that indeed $K=1$ (which we expect with probability 2/3, given $X=Y=1$) raises us to .5. 

# How well does this example generalize?

This example establishes the *possibility* of an empirically grounded approach to process tracing. But it relied on *very* informative results from a set of randomized trials. For less auspicious data generating processes the approach is much harder to ground. 

Say instead there were data of the form:



```{r, echo = FALSE, comment = ""}
df <- fabricate(X = add_level(N = 2, X = 0:1),
                K = add_level(N = 2, K = 0:1),
                Y = add_level(N = 2, Y = 0:1, share = 2*c(1/9, 1/18, 1/36, 1/18, 1/18, 1/36, 1/18, 1/9)))
# kable(df, digits = 3, caption = "Shares of each data profile given infinite data")

df_2 <- sapply(1:nrow(df), function(j) matrix(unlist(rep(df[j,], 36*df$share[j])), nrow = 4), simplify = F)
df_2 <- data.frame(t(do.call("cbind",df_2)))
# lm(Y ~ X, data = df_2)

colnames(df_2) <- c("X", "K", "Y", "share")
#dawid_bounds(df_2)
round(with(df_2, table(X, K))/36, 2)
round(with(df_2, table(K, Y))/36, 2)
round(with(df_2, table(X, Y))/36, 2)

```

```{r, include = FALSE}
lm(Y ~ K, weights = share, data = df)
lm(K ~ X, weights = share, data = df)
lm(Y ~ X, weights = share, data = df)
```

With this infinite data the average effect of $X$ on $K$ is $1/3$. The average effect of $K$ on $Y$ is $1/3$. And the average effect of $X$ on $Y$ is $1/9$. The biggest difference with the previous data is not the size of effects but the fact that the data is symmetric: $Y=0$ is not more rare than $Y=1$.

Looking at  $X$, $Y$, only, the data could arise from a process in which there are positive effect for 5/9 cases and negative effects for 4/9. In which case if $X=Y=1$, $X=1$ certainly caused $Y=1$. Alternatively it could also be that there is a positive effect for 1/9 and negative effects for none (and then $Y = 1$ always for 4/9 and $Y=0$ always for the last 4/9). This means that without taking account of $K$, the probability that $X=1$ caused $Y=1$ could be as high as 1 or as low as 1/5.^[That is: $1/9 / (1/9 + 4/9)$.] 

Knowing what we know about the $K$ relationship does not, in this case, alter these bounds. It is possible that, at each step, for 2/3 of the units *X* has a positive effect  and for 1/3 it has a negative effect (independently), meaning an overall positive effect for 5/9 and negative effect for 4/9 and so again if $X=Y=1$, $X=1$ certainly caused $Y=1$. And it is still possible that there is a positive effect for 1/3 at each step and no negative effects at any step (and $Y = 1$ always for 1/3 and $Y=0$ always for the last 1/3, independently at each step). So knowing the process in this case doesn't help. 

```{r, echo = FALSE}

inference_XY <- function(lambda_K, lambda_Y) {
  (lambda_K[2]*lambda_Y[2]+lambda_K[1]*lambda_Y[1]) /
  { (lambda_K[1]+lambda_K[3])*lambda_Y[1] + (lambda_K[2]+lambda_K[4])*lambda_Y[2] + lambda_Y[4]}} 

inference_XYK <- function(lambda_K, lambda_Y) {
  (lambda_K[2]*lambda_Y[2])/
  { (lambda_K[2] + lambda_K[4])*(lambda_Y[2] + lambda_Y[4])}}


lambda_K <- lambda_Y <- c(1/3, 2/3, 0, 0)
case1_XY  <-inference_XY (lambda_K, lambda_Y)
case1_XYX <-inference_XYK (lambda_K, lambda_Y)

lambda_K <- lambda_Y <- c(0, 1/3, 1/3, 1/3)
case2_XY  <-inference_XY (lambda_K, lambda_Y)
case2_XYK <- inference_XYK (lambda_K, lambda_Y)


lambda_K <- lambda_Y <- c(1/6, 1/2, 1/6, 1/6)
case3_XY  <-inference_XY (lambda_K, lambda_Y)
case3_XYK <- inference_XYK (lambda_K, lambda_Y)

lambda_K <- lambda_Y <- c(0, 8/10, 1/10, 1/10)
case4_XY  <-inference_XY (lambda_K, lambda_Y)
case4_XYK <- inference_XYK (lambda_K, lambda_Y)

```


Learning about $K$ does help, but only modestly. If you observe $K=1$ the upper bound on your beliefs would not budge from  1, but the  lower bound on your beliefs rises only modestly from  .25 rather than .2.^[Why? Because if you believe that 1/3 of units exhibit positive effects at each stage (and 1/3 have Y=1 or Y=0 regardless), then you expect to observe $X=Y=1$ share 5/9 of the time (i.e.  1/3 + 2/3 * 1/3) of which 1/9 are causal cases. Observing $K=1$ only rules out the possibility that the data was generated by the small set of cases that exhibit $K=0$ regardless and $Y=1$ regardless. These count for 1/9 cases, and so the causal cases as a share of the possible cases are now (1/9) / (4/9) rather than (1/9) / (5/9). If you do not see $K$ then you discount the possibility that X caused Y. Note that given you have seen $X=Y=1$ you expect to see $K$ with probability 4/5] 

<!-- bb  111 -->
<!-- bc   -->
<!-- bd  111 -->
<!-- cb -->
<!-- cc -->
<!-- cd  101 -->
<!-- db  111 -->
<!-- dc -->
<!-- dd  111 -->


<!-- Lets take effects running between 0 and 1 and the range of ways each could be produced. For simplicity we will assume the same ate for $X$ on $K$ and $K$ on $Y$.  -->

<!-- ```{r, echo = FALSE} -->
<!-- lambda_S_hi  <- function(ate) c((1 - ate)/2, (1 + ate)/2, 0, 0) -->

<!-- lambda_S_lo  <- function(ate) c(-min(0, ate), max(0,ate), (1-abs(ate))/2, (1-abs(ate))/2) -->

<!-- inferences <- function(ate) { -->
<!--  c( -->
<!--  inference_XY  (lambda_S_hi(ate), lambda_S_hi(ate)), -->
<!--  inference_XY  (lambda_S_lo(ate), lambda_S_lo(ate)), -->
<!--  inference_XYK (lambda_S_hi(ate), lambda_S_hi(ate)), -->
<!--  inference_XYK (lambda_S_lo(ate), lambda_S_lo(ate))) -->
<!-- } -->

<!-- ates <- seq(-.99,.99, length = 30) -->
<!-- y <- sapply(ates, inferences) -->

<!-- par(mfrow = c(1,3)) -->
<!-- plot(0:1, 0:1, type = "n", xlim = c(-1,1), ylim = c(0,1), main = "Possible beliefs given XY data only", xlab = "ATEs", ylab = "Posterior X caused Y") -->
<!-- polygon(c(ates, rev(ates)), c(y[1,], rev(y[2,])), col = "black") -->

<!-- plot(0:1, 0:1, type = "n", xlim = c(-1,1), ylim = c(0,1), main = "Possible beliefs given XYK data", xlab = "ATEs", ylab = "Posterior X caused Y") -->
<!-- polygon(c(ates, rev(ates)), c(y[3,], rev(y[4,])), col = "grey") -->

<!-- plot(0:1, 0:1, type = "n", xlim = c(-1,1), ylim = c(0,1), main = "Constraints on beliefs due to $K$", xlab = "ATEs", ylab = "Posterior X caused Y") -->
<!-- polygon(c(ates, rev(ates)), c(y[1,], rev(y[2,])), col = "black") -->
<!-- polygon(c(ates, rev(ates)), c(y[3,], rev(y[4,])), col = "grey") -->


<!-- ``` -->

<!-- The graph suggests that the constraints put on beliefs is quite modest. -->
<!-- The first panel shows, for any ate other than 0 beliefs are  constrained on the probabilty that X caused Y. -->


# Just imagine you could see the whole process

Lets extend the reasoning and say that you had a graph of the form $X \rightarrow K_1, \rightarrow \dots \rightarrow K_{n-1}  \rightarrow Y$. We are assuming a whole sequence of $n$ causal links and $n-1$ intermediate nodes.  We will assume background knowledge in the form of:

* Knowledge that the graph is correct
* Infinite experiments on the effect of each step in the chain on the next step.  

For simplicity we will assume that data from experiments in each step is of the same form. For this last point I  will introduce a little notation. Say that at step $k$ share $\lambda^k_a$ units exhibit negative effects, share $\lambda^k_b$ units exhibit positive effects, share  $\lambda^k_c$  exhibit $Y=0$ regardless and share  $\lambda^k_d$  exhibit $Y=1$ regardless. Define $\tau^k = \lambda^k_b - \lambda^k_a$ and $\rho^k = \lambda^k_d - \lambda^k_c$. Note that (dropping $k$ superscripts) any outcomes table from experiments with 50% of units assigned to treatment may be written in the form:

|   |   | Y                 |                   |   
|---|---|-------------------|-------------------|
|   |   | 0                 | 1                 |   
| X | 0 | $(1+\tau-\rho)/4$ | $(1-\tau+\rho)/4$ |   
|   | 1 | $(1-\tau-\rho)/4$ | $(1+\tau+\rho)/4$ |   

This has the advantage of describing data with just two parameters: one capturing treatment effects ($\tau$) and the other capturing how common $Y=1$ is overall. 


<!-- If $\lambda_a = 0$ then the off diagonals give $\lambda_d/2$ (top right) and  $\lambda_c/2$ (bottom left)  -->
<!-- and so the probability conditional on not being a  $b$ type is $\lambda_d/(\lambda_c+\lambda_d) = \frac{1-\tau+\rho}{2-2\tau} = \frac{1}{2} + \frac{\rho}{2-2\tau}$.  -->

<!-- Prob of obs data given type b or not b (x) at each step -->
<!-- bb  1 -->
<!-- xb .5 -->
<!-- bx  .5 -->
<!-- xx .25 -->

<!-- Two clues -->
<!-- bbb  1 -->
<!-- xbb .5 -->
<!-- bbx .5 -->
<!-- bxb .5 -->
<!-- xxb .25 -->
<!-- xbx .25 -->
<!-- bxx .25 -->
<!-- xxx .125 -->

<!-- Is this equal to probability b given X=Y=1 every step: ie b^n -->

```{r, echo = FALSE}
posterior1 <- function(ate) ate^2/(ate^2 + (ate*(1-ate))*(.5 + .5) + (1-ate)^2*(.25) ) 
# posterior1(1/3)

posterior2 <- function(ate) ate^3/(ate^3 + 
                                  3*(ate^2*(1-ate))*(.5^1)+  
                                  3*(ate*(1-ate)^2)*(.5^2)+ 
                                  (1-ate)^3*(.5^3) ) 
#  posterior2(.9)
```


```{r, echo = FALSE}
posterior_attribution <- function(step_ate = .9, n=2, rho = 0) {
  step_ate^n / sum(sapply(0:n, function(k)  choose(n, k)*(.5^k)*step_ate^(n-k)*(1-step_ate+rho)^k))
  }
posterior_attribution()

# posterior_attribution_check <- function(step_ate = .9, n=2, rho = 0) {
#   1 / sum(sapply(0:n, function(k)  choose(n, k)*((1-step_ate+rho)/(2*step_ate))^k))
#   }
# posterior_attribution_check()
# 
# posterior_attribution_check <- function(step_ate = .9, n=2, rho = 0) {
#   1 / (1+ (1-step_ate+rho)/(2*step_ate))^n
#   }
# posterior_attribution_check(step_ate = .25, n=20)

# m is the extent to which c's outnumber ds
posterior_attribution_total <- function(total_ate = .9, n=2, m = 1) {
  posterior_attribution(step_ate = total_ate^(1/n), n=n, rho = (1-m)*(1-total_ate^(1/n))/(1+m))
  }


```

If the effect were $\tau$ at each step the the effect of $X$ on $Y$ would be $\tau^n$. 

If one observed $K_j=1$ in every step, then the lowest posterior probability that $X$ caused $Y$ is:

$$\frac{1\times\tau^n}{\sum_{k=0}^nC(n, k)\frac{1}{2}^k\tau^{n-k}(1-\tau)^k}$$

<!-- $$\frac{\tau^n}{\sum_{k=0}^nC(n, k)\left(\frac{1}{2}\left(1+\frac{\rho}{1-\tau}\right)\right)^k\tau^{n-k}(1-\tau)^k}$$ -->
<!-- $$\frac{\tau^n}{\sum_{k=0}^nC(n, k)\left(\frac{1}{2}\left(1-\tau+\rho\right)\right)^k\tau^{n-k}}$$ -->

The numerator is the probability of observing $K$ in each step if indeed the relation was causal in each step times the probability of this. The denominator captures all the ways that such a result could have obtained given that between 0 and $n$ links may be  causal (here the function $C$,  standing for "choose,"  returns the binomial coefficient indicating the number of possible ways in which $k$ units are selected from $n$).

Using the binomial theorem this simplifies to:

<!-- $$\lim_{n \rightarrow \infty}\frac{1}{\sum_{k=0}^nC(n, k)\left(\frac{1-\tau}{2\tau}\right)^k}= \lim_{n \rightarrow \infty}\frac{1}{\left(1+\frac{1-\tau}{2\tau}\right)^n}= \lim_{n \rightarrow \infty} \left(\frac{2}{1+\frac{1}{\tau}}\right)^n = \frac{1}{\tau^{-.5}} = \tau^{.5}$$ -->

$$\left(\frac{2}{1+\frac{1}{\tau}}\right)^n$$

Consider then the situation in which the average effect of $X$ on $Y$ is 1/9, as above. Call this $\tau^*$. If there were two steps to the process then the average effect at each stage would be $\tau= 1/3$, as above. If there were 100 steps, and assuming the same type of relationship at each step, the ATE at each step would be 98%. For 1000 steps each step would have an ATE of 0.998. We are in a sense getting so close to the process that we have very little doubt that $K_j$ causes $K_{j+1}$ at any step.  

But, amazingly, I think; our confidence, even after seeing positive evidence in all of these steps, that $X$ caused $Y$ is quite weak. From 1 to 2 to 3 steps our confidence goes from `r posterior_attribution_total(total_ate = 1/9, n=1)`,  to `r posterior_attribution_total(total_ate = 1/9, n=2)`, to `r posterior_attribution_total(total_ate = 1/9, n=3)`; with 100 steps and $K_j=1$ in each one, the posterior rises to `r posterior_attribution_total(total_ate = 1/9, n=100)`, with 1000 steps it is `r posterior_attribution_total(total_ate = 1/9, n=1000)`.

More formally, if $\tau = \tau^{*\frac{1}{n}}$ in the limit we have:
$$\lim_{n \rightarrow \infty} \left(\frac{2}{1+\frac{1}{\tau^{*\frac{1}{n}}}}\right)^n = 
\lim_{n \rightarrow \infty} \tau^*\left(\frac{2}{1+\tau^{*\frac{1}{n}}}\right)^n=
\tau^{*\frac{1}{2}}$$

So even with infinite experiments at infinite points along a very well behaved causal chain and observation of data consistent with a causal effect at every point on the chain, the best we can do is limit our beliefs on whether $X$ caused $Y$ to between $1/3$ and 1. 

<!-- Consider then the situation in which the average effect of $X$ on $Y$ is 1/4. If $X = Y = 1$ then the lowest probability that X causd Y is if one believes $\lambda_a = 0, \lambda_b = 2/8,  \lambda_c = 3/8,  \lambda_d = 3/8$ and so the posterior is $\frac{\frac{2}{8}}{\frac{2}{8} + \frac{3}{8}} = \frac{2}{5}$. -->

<!-- Say now one had access to data on a clue $K$ and observe that the ATE of $X$ on $K$ and of $K$ on $Y$ were both $1/2$, giving rise to a total effect of $1/2 \times 1/2 = 1/4$. Then, on observing $K=1$, the posterior rises to (at least): `r round(posterior_attribution_total(total_ate = 1/4, n=2), 2)`. -->

```{r, include = FALSE}

#check
n = 1000
tau_star = 1/9
(2/(1+1/((tau_star^(1/n)))))^n
tau_star*(2/(1+tau_star^(1/n)))^n
(2/(1+tau_star^(1/n)))^n
```

```{r, echo = FALSE, include = FALSE}
steps = 1:50
ate = c(1/9, .25)
plot(steps, sapply(steps, function(j) posterior_attribution_total(total_ate = ate[1], n=j)), 
     ylim = c(0,1), 
     ylab = "posterior",
     xlab = "Number of steps observed on the causal chain",
     type = "l", 
     main = "Posterior inference given positive evidence on a causal chain")
text(max(steps)/2, posterior_attribution_total(total_ate = ate[1], n=500),  paste("ATE =", round(ate[1],2)))

for(s in 2:length(ate)){
  lines(steps, sapply(steps, function(j) posterior_attribution_total(total_ate = ate[s], n=j))) 
  text(max(steps)/2, posterior_attribution_total(total_ate = ate[s], n=500),  paste("ATE =", round(ate[s],2)))
}
abline(a = .5, b = 0, col = "red")
```





# References